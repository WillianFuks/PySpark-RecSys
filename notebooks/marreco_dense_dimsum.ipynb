{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pyspark.sql import functions as sfunc\n",
    "from pyspark.sql import types as stypes\n",
    "import math\n",
    "import sys\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = stypes.StructType().add(\"fv\", stypes.StringType()).add(\"sku\", stypes.StringType()).add(\"score\", stypes.FloatType())\n",
    "train_df = spark.read.csv('gs://lbanor/pyspark/train_query*.gz', header=True, schema=schema)\n",
    "train_df.createOrReplaceTempView('test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  sku,\n",
    "  ROW_NUMBER() OVER (ORDER BY SUM(1)) -1 idx\n",
    "FROM test1\n",
    "GROUP BY 1\n",
    "\"\"\"\n",
    "skus_rdd = spark.sql(query).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {row.sku: row.idx for row in skus_rdd.collect()}\n",
    "db = sc.broadcast(d)\n",
    "\n",
    "id_ = {value: key for key, value in d.items()}\n",
    "id_b = sc.broadcast(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_users_items = \"\"\"\n",
    "SELECT\n",
    "data\n",
    "FROM(\n",
    "  SELECT\n",
    "    fv,\n",
    "    COLLECT_LIST(STRUCT(sku, score * 2 AS score)) data\n",
    "  FROM test1\n",
    "  GROUP BY 1\n",
    ")\n",
    "WHERE size(data) between 2 and 20\n",
    "LIMIT 3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_rdd = spark.sql(query_users_items).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sparse(row):\n",
    "    tmp = sorted([(db.value[i.sku], i.score) for i in row.data], key=itemgetter(0))\n",
    "    return (SparseVector(len(db.value), [e[0] for e in tmp], [e[1] for e in tmp]),)\n",
    "\n",
    "t0 = time.time()\n",
    "mat = RowMatrix(users_rdd.map(lambda x: make_sparse(x)).toDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = mat.columnSimilarities(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
