{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'Out',\n",
       " 'SQLContext',\n",
       " 'SparkConf',\n",
       " 'SparkContext',\n",
       " 'SparkSession',\n",
       " '_',\n",
       " '_19',\n",
       " '_23',\n",
       " '_28',\n",
       " '_33',\n",
       " '_36',\n",
       " '_39',\n",
       " '_4',\n",
       " '_44',\n",
       " '_47',\n",
       " '_50',\n",
       " '_56',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i10',\n",
       " '_i11',\n",
       " '_i12',\n",
       " '_i13',\n",
       " '_i14',\n",
       " '_i15',\n",
       " '_i16',\n",
       " '_i17',\n",
       " '_i18',\n",
       " '_i19',\n",
       " '_i2',\n",
       " '_i20',\n",
       " '_i21',\n",
       " '_i22',\n",
       " '_i23',\n",
       " '_i24',\n",
       " '_i25',\n",
       " '_i26',\n",
       " '_i27',\n",
       " '_i28',\n",
       " '_i29',\n",
       " '_i3',\n",
       " '_i30',\n",
       " '_i31',\n",
       " '_i32',\n",
       " '_i33',\n",
       " '_i34',\n",
       " '_i35',\n",
       " '_i36',\n",
       " '_i37',\n",
       " '_i38',\n",
       " '_i39',\n",
       " '_i4',\n",
       " '_i40',\n",
       " '_i41',\n",
       " '_i42',\n",
       " '_i43',\n",
       " '_i44',\n",
       " '_i45',\n",
       " '_i46',\n",
       " '_i47',\n",
       " '_i48',\n",
       " '_i49',\n",
       " '_i5',\n",
       " '_i50',\n",
       " '_i51',\n",
       " '_i52',\n",
       " '_i53',\n",
       " '_i54',\n",
       " '_i55',\n",
       " '_i56',\n",
       " '_i57',\n",
       " '_i6',\n",
       " '_i7',\n",
       " '_i8',\n",
       " '_i9',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " '_pythonstartup',\n",
       " 'atexit',\n",
       " 'build_correlations',\n",
       " 'combine_skus',\n",
       " 'conf',\n",
       " 'defaultdict',\n",
       " 'exit',\n",
       " 'get_ipython',\n",
       " 'math',\n",
       " 'os',\n",
       " 'platform',\n",
       " 'py4j',\n",
       " 'query',\n",
       " 'quit',\n",
       " 'r',\n",
       " 'sc',\n",
       " 'schema',\n",
       " 'sfunc',\n",
       " 'spark',\n",
       " 'sql',\n",
       " 'sqlContext',\n",
       " 'sqlCtx',\n",
       " 'stypes',\n",
       " 'time',\n",
       " 'train_df',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "from pyspark.sql import functions as sfunc\n",
    "from pyspark.sql import types as stypes\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = stypes.StructType().add(\"fv\", stypes.StringType()).add(\"sku\", stypes.StringType()).add(\"score\", stypes.FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = spark.read.csv('gs://lbanor/pyspark/train_query*.gz', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(fv='3383270414872112082', sku='MO578SHF77RTI', score=0.5),\n",
       " Row(fv='7143168022217708588', sku='DA923SHF54UJP', score=0.5),\n",
       " Row(fv='8844960186636261737', sku='LU621ACM67NYU', score=0.5)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = train_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(fv='3383270414872112082', sku='MO578SHF77RTI', score=0.5)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42915448"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.createOrReplaceTempView('test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_correlations(row):\n",
    "    return [{\"sku\": e.sku, \"corr\": [{\"sku\": i.sku, \"score\": e.score * i.score} for i in row]} for e in row]\n",
    "sqlContext.udf.register(\"BUILD_CORRELATIONS\", build_correlations, stypes.ArrayType(stypes.StructType(fields=[stypes.StructField(\"sku\", stypes.StringType(), False), stypes.StructField(\"corr\", stypes.ArrayType(stypes.StructType(fields=[stypes.StructField(\"sku\", stypes.StringType(), False), stypes.StructField(\"score\", stypes.FloatType(), False)])), False)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_skus(ref_sku, row):\n",
    "    d = defaultdict(float)\n",
    "    ref_norm = 0.0\n",
    "    for inner_row in row:\n",
    "        for e in inner_row:\n",
    "            d[e.sku] += e.score\n",
    "            if e.sku == ref_sku:\n",
    "                ref_norm += e.score\n",
    "    ref_norm = math.sqrt(ref_norm)\n",
    "    return {\"norm\": ref_norm, \"corr\": [{\"sku\": key, \"similarity\": value / ref_norm} for key, value in d.items()]}\n",
    "sqlContext.udf.register(\"COMBINE_SKUS\", combine_skus, stypes.StructType(fields=[stypes.StructField(\"norm\", stypes.FloatType(), False), stypes.StructField(\"corr\", stypes.ArrayType(stypes.StructType(fields=[stypes.StructField(\"sku\", stypes.StringType(), False), stypes.StructField(\"similarity\", stypes.FloatType(), False)]) ) )]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  data.sku sku,\n",
    "  COMBINE_SKUS(data.sku, COLLECT_LIST(data.corr)) data\n",
    "FROM(\n",
    "  SELECT\n",
    "  EXPLODE(BUILD_CORRELATIONS(data)) data\n",
    "  FROM(\n",
    "    SELECT\n",
    "      fv,\n",
    "      COLLECT_LIST(STRUCT(sku, score)) data\n",
    "    FROM test1\n",
    "    GROUP BY\n",
    "      fv\n",
    "    HAVING SIZE(data) > 1 AND SIZE(data) < 200\n",
    "  )\n",
    ")\n",
    "GROUP BY\n",
    "  data.sku\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1 = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1.createOrReplaceTempView('test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_extract_norms = \"\"\"\n",
    "SELECT\n",
    "  sku,\n",
    "  data.norm norm\n",
    "FROM test2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481.6083595752716\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "r2 = {e.sku: e.norm for e in spark.sql(query_extract_norms).collect()}\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2_broad = sc.broadcast(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_corrs(corrs):\n",
    "    return [{\"sku\": e.sku, \"similarity\": e.similarity / r2_broad.value[e.sku]} for e in corrs]\n",
    "sqlContext.udf.register(\"NORMALIZE_CORRS\", normalize_corrs, stypes.ArrayType(stypes.StructType(fields=[stypes.StructField(\"sku\", stypes.StringType(), False), stypes.StructField(\"similarity\", stypes.FloatType(), False)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_query = \"\"\"\n",
    "select\n",
    "sku,\n",
    "NORMALIZE_CORRS(data.corr) corr\n",
    "FROM test2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = spark.sql(final_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381.65184354782104\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "final.head(1)\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
